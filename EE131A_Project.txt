1)  b) For this random variable, P(X=k) = (100 nCr k) (0.2)^k (0.8)^(100-k)
       By taking the ratio of runs X=k and X=k+1, we can get that the maximum
       value occurs at k = 20, when the ratio drops below 1.
    c) From the simulation, the max value is usually 20, but the runs can
       range from 19-21. This fluctuation is due to the limited number of samples
       that we are using, but it shows that 10000 does give a fairly good
       approximation as a large N.

2)  Here are some values I got for the mean and variance from one run of
    my script:
                Expected    10      10^4    10^7
    mean        0.0000      0.5615  -0.0102 -4.110e-04
    variance    1.0000      1.3722  1.0122  0.9999

    Here are the values I got for Q from one run of my script:

            Expected    10      10^4    10^7 Samples
    Q(1)    0.1587      0.4000  0.1534  0.1586
    Q(2)    0.0228      0.1000  0.0248  0.0228
    Q(3)    0.0013      0.0000  0.0022  0.0013

    From the charts above, we can see that as the number of samples increased
    the values for mean, variance, and Q match the expected values more
    closely. This trend can also be seen in the figures with expected normal
    curve super-imposed onto the generated normal pdf. The pdf of 10 samples
    does not match curve at all, but as the number of samples increases to 10^4,
    it becomes more acceptable. Then, at 10^7 samples, the pdf almost exacly
    matches the expected curve.

3)  a)  To generate the distribution of 2 rolled dice, I simply generated two
        discrete uniform distributions with values from 1 - 6 and added them
        together. To find the probability of winning on the first roll, I just
        added the probablility of rolling a 7 and 11. The probability was
        around 0.22.

    b)  To calculated the probability of winning given the first roll was a
        5 I created a function (Q3SecondRollWinning.m) to simulate the results
        of games that lasted longer than 1 roll. This function took as parameters
        the generated dice sum probabilities (from part a) and the value of
        the first roll. First, I calculate the cdf by taking a cumulative sum
        of the pdf. Then, I generate a uniform random number and find which
        roll it cooresponds to. To do this, I find the smallest roll whose
        cdf value is greater than the generated random value. If the roll results
        in a 7, it registers as a loss; if it results as the previously rolled
        value, it registers as a win. Finally, if the roll is something other
        than those two values, it keeps repeating. When given as input a 5
        for the sum of the first roll, the simulation shows a probability of
        about 0.4 over the 10000 runs made.

    c)  To calculate the probablility of winning the game, I created another
        funtion (Q3FullGameOfCraps.m) to simulate a complete run of the game.
        For this, I used the same method as in part b to simulate a roll based
        on the probabilities generated in part a. Then, I used a switch statement
        to handle the different cases. If a 7 or 11 was rolled, the game would
        end with a win. If a 2, 3, or 12 was rolled, the game would end with
        a loss. Else, I would call the function written in part b to finish
        off the game. Running this simulation 10000 times, I got the probability
        of winning a game of craps to be about 0.49.

4)  a)  To generate a Laplacian distribution, I first calculated the cdf by
        taking a running integral of the pdf (by hand). Then I took the inverse
        of the cdf and plugged in random values generated using a uniform distribution.
        I only generated positive values because the cdf I found was only for
        the right side of the pdf (due to the absolute value), so I randomly
        assigned some values to be positive and some to be negative. This
        method was implemented in the Q4LaplacianDistGen.m function.

    b)  To simulate the transmission of 10000 bits, I first created 2 separate
        distributions, one for transmitting a 1 and one for transmitting a zero.
        The number of samples in each distribution was determined by a binomial
        random variable with N = 10000 and p = 0.5, since a 1 and 0 are equiprobable
        Then, to calculate the probability of having and error, I counted the
        the number of values above or below 0, and divided by the number of
        those bits sent. During one run, I got the following values:

            Probability of false zero: 0.029809
            Probability of false one: 0.028203

    c)  To find the error probability analytically, I integrated the pdf of
        a LaPlacian distribution with mean 0 and alpha sqrt(2) from 2 to infinity.
        This gave me an error probability of 0.5*exp(-2 * sqrt(2)), which equals
        0.0296. The values I get from the simulation (seen above in part b) are
        very close to this expected value.

5)  b)  Since X was a uniform RV, it was easy to find the mean and variance:
        E(x)   = (a + b) / 2 = (1 + 6) / 2 = 3.5
        Var(x) = (b - a)^2 / 12 = (6 - 1)^2 / 12 = 25/12

        When adding these RV's, we get the following properties:
        E(S_n) = n * E(x)
        Var(S_n) = n * Var(x)
        The following is a chart for the different S_n's we used:

        n   mean    variance
        1   3.5     25/12
        5   17.5    125/12
        10  35      125/6
        50  175     625/6